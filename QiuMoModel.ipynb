{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599104773355",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "140 images loaded\n"
    }
   ],
   "source": [
    "# path = \"E:\\\\ML\\\\ComputerVision\\\\QiuMo\\\\dataset\\\\\"\n",
    "# file_names = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "# print(str(len(file_names)) + ' images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_count = 0\n",
    "# m_count = 0\n",
    "training_size = 60\n",
    "test_size = 10\n",
    "training_images = []\n",
    "training_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_dir_train = \"E:\\\\ML\\\\ComputerVision\\\\QiuMo\\\\dataset\\\\train\\\\Qiuqiu\\\\\"\n",
    "# m_dir_train = \"E:\\\\ML\\\\ComputerVision\\\\QiuMo\\\\dataset\\\\train\\\\Momo\\\\\"\n",
    "# q_dir_val = \"E:\\\\ML\\\\ComputerVision\\\\QiuMo\\\\dataset\\\\test\\\\Qiuqiu\\\\\"\n",
    "# m_dir_val = \"E:\\\\ML\\\\ComputerVision\\\\QiuMo\\\\dataset\\\\test\\\\Momo\\\\\"\n",
    "\n",
    "# def make_dir(directory):\n",
    "#         if os.path.exists(directory):\n",
    "#             shutil.rmtree(directory)\n",
    "#         os.makedirs(directory)\n",
    "\n",
    "# make_dir(q_dir_train)\n",
    "# make_dir(m_dir_train)\n",
    "# make_dir(q_dir_val)\n",
    "# make_dir(m_dir_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training and Test Data Extraction Complete\n"
    }
   ],
   "source": [
    "# def getZeros(number):\n",
    "#     if(number > 10 and number < 100):\n",
    "#         return \"0\"\n",
    "#     if(number < 10):\n",
    "#         return \"00\"\n",
    "#     else:\n",
    "#         return \"\"\n",
    "        \n",
    "# for i, f in enumerate(file_names):\n",
    "#     if file_names[i][0] == 'Q':\n",
    "#         q_count += 1\n",
    "#         img = cv2.imread(path+f)\n",
    "#         img = cv2.resize(img, (size,size), interpolation=cv2.INTER_AREA)\n",
    "#         if q_count <= training_size:\n",
    "#             training_images.append(img)\n",
    "#             training_labels.append(1)\n",
    "#             cv2.imwrite(q_dir_train+'q_'+str(getZeros(q_count))+str(q_count)+'.jpg', img)\n",
    "#         if q_count > training_size and q_count <= training_size + test_size:\n",
    "#             test_images.append(img)\n",
    "#             test_labels.append(1)\n",
    "#             cv2.imwrite(q_dir_val+'q_'+str(getZeros(q_count-60))+str(q_count-60)+'.jpg', img)\n",
    "    \n",
    "#     if file_names[i][0] =='M':\n",
    "#         m_count += 1\n",
    "#         img = cv2.imread(path+f)\n",
    "#         img = cv2.resize(img, (size,size), interpolation=cv2.INTER_AREA)\n",
    "#         if m_count <= training_size:\n",
    "#             training_images.append(img)\n",
    "#             training_labels.append(0)\n",
    "#             cv2.imwrite(m_dir_train+'m_'+str(getZeros(m_count))+str(m_count)+'.jpg', img)\n",
    "#         if m_count > training_size and m_count <= training_size + test_size:\n",
    "#             test_images.append(img)\n",
    "#             test_labels.append(0)\n",
    "#             cv2.imwrite(m_dir_val+'m_'+str(getZeros(m_count-60))+str(m_count-60)+'.jpg', img)\n",
    "    \n",
    "#     if q_count == training_size + test_size and m_count == training_size + test_size:\n",
    "#         break\n",
    "\n",
    "\n",
    "# print(\"Training and Test Data Extraction Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training data length:  120\nTest data length:  20\n"
    }
   ],
   "source": [
    "# print('Training data length: ', len(training_images))\n",
    "# print('Test data length: ', len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('QM_training_data.npz', np.array(training_images))\n",
    "# np.savez('QM_training_labels.npz', np.array(training_labels))\n",
    "# np.savez('QM_test_data.npz', np.array(test_images))\n",
    "# np.savez('QM_test_labels.npz', np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datasetname):\n",
    "    npzfile = np.load(datasetname + '_training_data.npz')\n",
    "    train = npzfile['arr_0']\n",
    "\n",
    "    npzfile = np.load(datasetname + '_training_labels.npz')\n",
    "    train_labels = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + '_test_data.npz')\n",
    "    test = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + '_test_labels.npz')\n",
    "    test_labels = npzfile['arr_0']\n",
    "\n",
    "    return (train, train_labels), (test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('QM_training_data.npz')['arr_0']\n",
    "y_train = np.load('QM_training_labels.npz')['arr_0']\n",
    "x_test = np.load('QM_test_data.npz')['arr_0']\n",
    "y_test = np.load('QM_test_labels.npz')['arr_0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(120, 150, 150, 3)\n(120, 1)\n(20, 150, 150, 3)\n(20, 1)\n"
    }
   ],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n_________________________________________________________________\nactivation_10 (Activation)   (None, 148, 148, 32)      0         \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 72, 72, 32)        9248      \n_________________________________________________________________\nactivation_11 (Activation)   (None, 72, 72, 32)        0         \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 36, 36, 32)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 34, 34, 64)        18496     \n_________________________________________________________________\nactivation_12 (Activation)   (None, 34, 34, 64)        0         \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 17, 17, 64)        0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 15, 15, 128)       73856     \n_________________________________________________________________\nactivation_13 (Activation)   (None, 15, 15, 128)       0         \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6272)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               802944    \n_________________________________________________________________\nactivation_14 (Activation)   (None, 128)               0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 64)                8256      \n_________________________________________________________________\nactivation_15 (Activation)   (None, 64)                0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 65        \n_________________________________________________________________\nactivation_16 (Activation)   (None, 1)                 0         \n=================================================================\nTotal params: 913,761\nTrainable params: 913,761\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "epochs = 20\n",
    "\n",
    "img_row = x_train[0].shape[0]\n",
    "img_cols = x_train[1].shape[0]\n",
    "input_shape = (img_row, img_cols, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam',  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 120 samples, validate on 20 samples\nEpoch 1/20\n120/120 [==============================] - 2s 15ms/sample - loss: 0.7196 - accuracy: 0.5167 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 2/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.6933 - accuracy: 0.4833 - val_loss: 0.6932 - val_accuracy: 0.5000\nEpoch 3/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.6904 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\nEpoch 4/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.7111 - accuracy: 0.4750 - val_loss: 0.6922 - val_accuracy: 0.6000\nEpoch 5/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.6864 - accuracy: 0.5750 - val_loss: 0.6570 - val_accuracy: 0.8000\nEpoch 6/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.6356 - accuracy: 0.5417 - val_loss: 0.6177 - val_accuracy: 0.7000\nEpoch 7/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.7575 - accuracy: 0.6833 - val_loss: 0.8085 - val_accuracy: 0.8000\nEpoch 8/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.7514 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.5000\nEpoch 9/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.7026 - accuracy: 0.4917 - val_loss: 0.6935 - val_accuracy: 0.5000\nEpoch 10/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.6950 - accuracy: 0.4917 - val_loss: 0.6939 - val_accuracy: 0.5000\nEpoch 11/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.6903 - accuracy: 0.5583 - val_loss: 0.6939 - val_accuracy: 0.3500\nEpoch 12/20\n120/120 [==============================] - 1s 12ms/sample - loss: 0.6901 - accuracy: 0.5417 - val_loss: 0.6830 - val_accuracy: 0.8000\nEpoch 13/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.6370 - accuracy: 0.7000 - val_loss: 0.5953 - val_accuracy: 0.7500\nEpoch 14/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.5191 - accuracy: 0.7417 - val_loss: 0.5725 - val_accuracy: 0.7000\nEpoch 15/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.4961 - accuracy: 0.7417 - val_loss: 0.5468 - val_accuracy: 0.6500\nEpoch 16/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.5125 - accuracy: 0.7750 - val_loss: 0.6652 - val_accuracy: 0.7500\nEpoch 17/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.4111 - accuracy: 0.8417 - val_loss: 0.5444 - val_accuracy: 0.7500\nEpoch 18/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.4073 - accuracy: 0.8083 - val_loss: 0.6491 - val_accuracy: 0.7500\nEpoch 19/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.3387 - accuracy: 0.8667 - val_loss: 0.6327 - val_accuracy: 0.7500\nEpoch 20/20\n120/120 [==============================] - 2s 13ms/sample - loss: 0.2896 - accuracy: 0.8667 - val_loss: 0.8353 - val_accuracy: 0.8000\n20/20 [==============================] - 0s 6ms/sample - loss: 0.8353 - accuracy: 0.8000\nTest loss: 0.835340678691864\nTest accuracy: 0.8\n"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = model\n",
    "\n",
    "def draw_test(name, pred, input_im):\n",
    "    BLACK = [0,0,0]\n",
    "    if pred == \"[0]\":\n",
    "        pred = \"Momo\"\n",
    "    if pred == \"[1]\":\n",
    "        pred = \"Qiuqiu\"\n",
    "    expanded_image = cv2.copyMakeBorder(input_im, 0, 0, 0, imageL.shape[0] ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    #expanded_image = cv2.cvtColor(expanded_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(expanded_image, str(pred), (252, 70) , cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "for i in range(0,5):\n",
    "    rand = np.random.randint(0,len(x_test))\n",
    "    input_im = x_test[rand]\n",
    "\n",
    "    imageL = cv2.resize(input_im, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Test Image\", imageL)\n",
    "\n",
    "    input_im = input_im.reshape(1,150,150,3) \n",
    "    \n",
    "    ## Get Prediction\n",
    "    res = str(classifier.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "\n",
    "    draw_test(\"Prediction\", res, imageL) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_im = cv2.imread('./dataset/Validation/T12.jpg')\n",
    "input_im = cv2.resize(input_im, (size,size), interpolation=cv2.INTER_AREA)\n",
    "imageL = cv2.resize(input_im, None, fx=2, fy=2, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"Test Image\", imageL)\n",
    "input_im = input_im.reshape(1,150,150,3) \n",
    "res = str(classifier.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "draw_test(\"Prediction\", res, imageL) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}